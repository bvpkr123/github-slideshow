{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End_course_test_Vijay.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KYst_O2DNCI-",
        "nOtdvTnmPNEA",
        "4YZGHTvYQ3Wq",
        "xlkFAU1SD61-",
        "gIBuvXNtDVua",
        "qVuKKUE6Dr-0",
        "GRd__RAjDKnN",
        "LBywYsPaC4Ny",
        "IGYK0xx9CbeK",
        "3Row-hBnTysE"
      ],
      "mount_file_id": "1J4fzG8kvmqVSGGTVAbY4fvb8mIYMT3CF",
      "authorship_tag": "ABX9TyPQPJ8vpPZfurfK+WLxOP0M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bvpkr123/github-slideshow/blob/master/Fashion_MNSIT_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9yOykCMMtOT",
        "colab_type": "text"
      },
      "source": [
        "#Importing all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b285JiKCLKou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as  plt\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.losses import categorical_crossentropy,sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam,RMSprop,SGD\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYst_O2DNCI-",
        "colab_type": "text"
      },
      "source": [
        "#Importing Fashion dataset and splitting it into Train & Test\n",
        "#Converting the labels to categorical of float32\n",
        "#Reshaping images dataset-> scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mULMxb46_azW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the fashion data set and splitting Splitting MNIST dataset into train,test\n",
        "(train_images, train_labels), (test_images, test_labels)=tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUbdh8JcpLTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "78680871-571a-46de-f871-1d89870eef5a"
      },
      "source": [
        "#converting labels to categorical and with num_class as 10 ( Outputs )\n",
        "print ('Before scaling',train_images[0])\n",
        "\n",
        "#Scalling the image dataset\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "print('After scaling',train_images[0])"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before scaling [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "After scaling [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
            "  0.         0.00392157 0.01568627 0.         0.         0.\n",
            "  0.         0.00392157 0.00392157 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
            "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
            "  0.01568627 0.         0.         0.01176471]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n",
            "  0.56470588 0.48235294 0.09019608 0.         0.         0.\n",
            "  0.         0.04705882 0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
            "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
            "  0.30196078 0.50980392 0.28235294 0.05882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n",
            "  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n",
            "  0.55294118 0.34509804 0.6745098  0.25882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
            "  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n",
            "  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n",
            "  0.48235294 0.76862745 0.89803922 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
            "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
            "  0.8745098  0.96078431 0.67843137 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n",
            "  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n",
            "  0.8627451  0.95294118 0.79215686 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.01176471 0.\n",
            "  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n",
            "  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n",
            "  0.88627451 0.77254902 0.81960784 0.20392157]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.02352941 0.\n",
            "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
            "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
            "  0.96078431 0.46666667 0.65490196 0.21960784]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.01568627 0.         0.\n",
            "  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n",
            "  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n",
            "  0.85098039 0.81960784 0.36078431 0.        ]\n",
            " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n",
            "  0.00784314 0.         0.         0.         0.         0.\n",
            "  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n",
            "  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
            "  0.85490196 1.         0.30196078 0.        ]\n",
            " [0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
            "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
            "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
            "  0.87843137 0.95686275 0.62352941 0.        ]\n",
            " [0.         0.         0.         0.         0.07058824 0.17254902\n",
            "  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n",
            "  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n",
            "  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n",
            "  0.91372549 0.93333333 0.84313725 0.        ]\n",
            " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n",
            "  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n",
            "  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
            "  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n",
            "  0.8627451  0.90980392 0.96470588 0.        ]\n",
            " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
            "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
            "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
            "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
            "  0.87058824 0.89411765 0.88235294 0.        ]\n",
            " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n",
            "  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n",
            "  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n",
            "  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n",
            "  0.8745098  0.87843137 0.89803922 0.11372549]\n",
            " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n",
            "  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
            "  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n",
            "  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n",
            "  0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
            " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
            "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
            "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
            "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
            "  0.70980392 0.80392157 0.80784314 0.45098039]\n",
            " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n",
            "  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n",
            "  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n",
            "  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n",
            "  0.65490196 0.69411765 0.82352941 0.36078431]\n",
            " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
            "  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n",
            "  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n",
            "  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n",
            "  0.75294118 0.84705882 0.66666667 0.        ]\n",
            " [0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
            "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
            "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
            "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
            "  0.38823529 0.22745098 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n",
            "  0.1372549  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOtdvTnmPNEA",
        "colab_type": "text"
      },
      "source": [
        "# Defining Class\n",
        "# Plotting first 25 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NYI8exfPKxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining 10 class name for output\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duL5-fpjsJ7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "99d80a30-df79-44c5-a4ac-d274ee3fe7e9"
      },
      "source": [
        "n=25\n",
        "plt.figure(figsize=(20,4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n,i+1)\n",
        "    lbl=class_names[train_labels[i]]\n",
        "    plt.title(lbl)\n",
        "    plt.imshow(train_images[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# plt.imshow(train_images[i], cmap='gray_r')\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YZGHTvYQ3Wq",
        "colab_type": "text"
      },
      "source": [
        "#Reshaping the train & test to 28x28x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1fZGV4t3iDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2bc0c7b9-88a0-4da8-e245-28894909a6aa"
      },
      "source": [
        "#Reshaping train_images & test_images\n",
        "print('Before reshaping')\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "\n",
        "train_images=array(train_images).reshape(60000, 28,28,1)\n",
        "test_images=array(test_images).reshape(10000,28,28,1)\n",
        "\n",
        "print('After reshaping')\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before reshaping\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "After reshaping\n",
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlkFAU1SD61-",
        "colab_type": "text"
      },
      "source": [
        "#Building CNN for the fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gwFyVpLvF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f40a0923-6094-4426-db42-795c8e956d29"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#Single layer perceptron\n",
        "model.add(Conv2D(32, (3,3),strides=(1,1), input_shape=[28,28,1]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_65 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_184 (Activation)  (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_62 (Flatten)         (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 128)               692352    \n",
            "_________________________________________________________________\n",
            "activation_185 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_186 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 693,962\n",
            "Trainable params: 693,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIBuvXNtDVua",
        "colab_type": "text"
      },
      "source": [
        "#Compiling the model with **Sparse Categorical Crossentropy** and fitting it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3M_thSMPAX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0b44e5c-1f44-478a-af9b-b5c7d32b9bf2"
      },
      "source": [
        "OPTIMIZER= Adam()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(train_images,train_labels,batch_size=1000,epochs=30)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.7083 - accuracy: 0.7672\n",
            "Epoch 2/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8605\n",
            "Epoch 3/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8772\n",
            "Epoch 4/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.3269 - accuracy: 0.8860\n",
            "Epoch 5/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.3053 - accuracy: 0.8935\n",
            "Epoch 6/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2868 - accuracy: 0.8990\n",
            "Epoch 7/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2743 - accuracy: 0.9032\n",
            "Epoch 8/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2649 - accuracy: 0.9056\n",
            "Epoch 9/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2521 - accuracy: 0.9112\n",
            "Epoch 10/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2447 - accuracy: 0.9130\n",
            "Epoch 11/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2380 - accuracy: 0.9154\n",
            "Epoch 12/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.9192\n",
            "Epoch 13/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2170 - accuracy: 0.9236\n",
            "Epoch 14/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2136 - accuracy: 0.9253\n",
            "Epoch 15/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2033 - accuracy: 0.9279\n",
            "Epoch 16/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1997 - accuracy: 0.9297\n",
            "Epoch 17/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1919 - accuracy: 0.9320\n",
            "Epoch 18/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1885 - accuracy: 0.9330\n",
            "Epoch 19/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1818 - accuracy: 0.9355\n",
            "Epoch 20/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1765 - accuracy: 0.9371\n",
            "Epoch 21/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1712 - accuracy: 0.9394\n",
            "Epoch 22/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1643 - accuracy: 0.9419\n",
            "Epoch 23/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1615 - accuracy: 0.9431\n",
            "Epoch 24/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1583 - accuracy: 0.9440\n",
            "Epoch 25/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1525 - accuracy: 0.9462\n",
            "Epoch 26/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1487 - accuracy: 0.9476\n",
            "Epoch 27/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9489\n",
            "Epoch 28/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1383 - accuracy: 0.9517\n",
            "Epoch 29/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1338 - accuracy: 0.9536\n",
            "Epoch 30/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1317 - accuracy: 0.9538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVuKKUE6Dr-0",
        "colab_type": "text"
      },
      "source": [
        "#Compiling the model with **Categorical Crossentropy** and fitting it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH1j9yTNQFIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "192cd5f4-61f5-4965-8eee-eaf196742528"
      },
      "source": [
        "train_labels=tf.keras.utils.to_categorical(train_labels, num_classes=10, dtype='float32')\n",
        "test_labels=tf.keras.utils.to_categorical(test_labels, num_classes=10, dtype='float32')\n",
        "OPTIMIZER= Adam()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(train_images,train_labels,batch_size=1000,epochs=30)\n"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1321 - accuracy: 0.9537\n",
            "Epoch 2/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1221 - accuracy: 0.9581\n",
            "Epoch 3/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9598\n",
            "Epoch 4/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1154 - accuracy: 0.9603\n",
            "Epoch 5/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1113 - accuracy: 0.9617\n",
            "Epoch 6/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1085 - accuracy: 0.9638\n",
            "Epoch 7/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.9650\n",
            "Epoch 8/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0996 - accuracy: 0.9672\n",
            "Epoch 9/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0987 - accuracy: 0.9671\n",
            "Epoch 10/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 0.9691\n",
            "Epoch 11/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0895 - accuracy: 0.9708\n",
            "Epoch 12/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0866 - accuracy: 0.9721\n",
            "Epoch 13/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9730\n",
            "Epoch 14/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9727\n",
            "Epoch 15/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0852 - accuracy: 0.9714\n",
            "Epoch 16/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9767\n",
            "Epoch 17/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0729 - accuracy: 0.9769\n",
            "Epoch 18/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9782\n",
            "Epoch 19/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9805\n",
            "Epoch 20/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 0.9789\n",
            "Epoch 21/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0645 - accuracy: 0.9795\n",
            "Epoch 22/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.9817\n",
            "Epoch 23/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0564 - accuracy: 0.9833\n",
            "Epoch 24/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9842\n",
            "Epoch 25/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9837\n",
            "Epoch 26/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0516 - accuracy: 0.9847\n",
            "Epoch 27/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 0.9854\n",
            "Epoch 28/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0490 - accuracy: 0.9853\n",
            "Epoch 29/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0455 - accuracy: 0.9870\n",
            "Epoch 30/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRd__RAjDKnN",
        "colab_type": "text"
      },
      "source": [
        "#Saving the model -> Loading it again -> Evaluating to check accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSzwJ9a1PiR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug5Yx4YC6jDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "494294f6-48db-4162-fbe7-dcf800793ba4"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model('my_model.h5')\n",
        "loaded_model.summary()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_65 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_184 (Activation)  (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_62 (Flatten)         (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 128)               692352    \n",
            "_________________________________________________________________\n",
            "activation_185 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_186 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 693,962\n",
            "Trainable params: 693,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diTvU1LY66rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e34f9fcf-e2bc-4a6d-c9ab-220fabd8630a"
      },
      "source": [
        "score = loaded_model.evaluate(train_images, train_labels)\n",
        "print(\"Test loss:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0437 - accuracy: 0.9873\n",
            "Test loss: 0.043698474764823914\n",
            "Test accuracy: 0.9873166680335999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBywYsPaC4Ny",
        "colab_type": "text"
      },
      "source": [
        "# Displaying confusion matrix and its classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pNMlHrS86MO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "729d8a0b-7b9a-4a16-870b-156508b21100"
      },
      "source": [
        "Test_labels=np.argmax(test_labels,axis=1)\n",
        "model_confusion_matrix=confusion_matrix(Test_labels,y_pred)\n",
        "print(model_confusion_matrix)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[840   0  15  17   7   2 111   0   8   0]\n",
            " [  1 973   2  14   4   0   5   0   1   0]\n",
            " [ 15   0 836   7  64   1  77   0   0   0]\n",
            " [ 10   4   6 913  30   0  35   0   2   0]\n",
            " [  0   0  24  22 905   0  49   0   0   0]\n",
            " [  0   0   0   0   0 978   0  12   0  10]\n",
            " [ 58   0  35  24  63   0 813   0   7   0]\n",
            " [  0   0   0   0   0   8   0 973   1  18]\n",
            " [  4   2   3   2   3   1  10   4 971   0]\n",
            " [  0   0   0   0   0   6   1  31   0 962]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj2oqgEx9mED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bb9e4da5-374d-47ce-8c5d-9a284d03361b"
      },
      "source": [
        "print(classification_report(Test_labels, y_pred, target_names=class_names))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.91      0.84      0.87      1000\n",
            "     Trouser       0.99      0.97      0.98      1000\n",
            "    Pullover       0.91      0.84      0.87      1000\n",
            "       Dress       0.91      0.91      0.91      1000\n",
            "        Coat       0.84      0.91      0.87      1000\n",
            "      Sandal       0.98      0.98      0.98      1000\n",
            "       Shirt       0.74      0.81      0.77      1000\n",
            "     Sneaker       0.95      0.97      0.96      1000\n",
            "         Bag       0.98      0.97      0.98      1000\n",
            "  Ankle boot       0.97      0.96      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGYK0xx9CbeK",
        "colab_type": "text"
      },
      "source": [
        "#Counting FP & FN from confusion matrix ie., Misclassification count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLz0pRWBta-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "37a0f921-8f02-439b-c606-e10bc6f70e10"
      },
      "source": [
        "mis_cal_count=0\n",
        "for i in range(10):\n",
        "  for j in range(10):\n",
        "    if i!=j:\n",
        "      mis_cal_count=miss_cal_count+model_confusion_matrix[i][j]\n",
        "print('Total count of Misclassification:',mis_cal_count) "
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total count of Misclassification: 836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Row-hBnTysE",
        "colab_type": "text"
      },
      "source": [
        "#Evaluating with different hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U4pgQzpEL07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8bb78ef-590a-42d2-8244-97eed71b823e"
      },
      "source": [
        "epochs=[10,30,50]\n",
        "batch_size=[500,1000,1500]\n",
        "Optimizer=['Adam','RMSprop','SGD']\n",
        "j=0\n",
        "result={}\n",
        "for o in range(len(Optimizer)):\n",
        "  for e in range(len(epochs)):\n",
        "    for b in range(len(batch_size)):\n",
        "      \n",
        "      #Loading data\n",
        "      (train_images, train_labels), (test_images, test_labels)=tf.keras.datasets.fashion_mnist.load_data()\n",
        "      \n",
        "      #Scalling the image dataset\n",
        "      train_images = train_images / 255.0\n",
        "      test_images = test_images / 255.0\n",
        "      train_images=array(train_images).reshape(60000, 28,28,1)\n",
        "      test_images=array(test_images).reshape(10000,28,28,1)\n",
        "      \n",
        "      #Creating Basic CNN\n",
        "      model = Sequential()\n",
        "      model.add(Conv2D(32, (3,3),strides=(1,1), input_shape=[28,28,1]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPool2D(pool_size=(2,2)))\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(128))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(Dense(10))\n",
        "      model.add(Activation('softmax'))\n",
        "\n",
        "      train_labels=tf.keras.utils.to_categorical(train_labels, num_classes=10, dtype='float32')\n",
        "      test_labels=tf.keras.utils.to_categorical(test_labels, num_classes=10, dtype='float32')\n",
        "      \n",
        "      #Model Copilation and fitting\n",
        "      model.compile(loss='categorical_crossentropy', optimizer=Optimizer[o], metrics=['accuracy'])\n",
        "      model.fit(train_images,train_labels,batch_size=batch_size[b],epochs=epochs[e])\n",
        "      score = model.evaluate(train_images, train_labels)\n",
        "      result2[Optimizer[o]+str(epochs[e])+str(batch_size[b])]=score[1]\n",
        "      print(Optimizer[o],epochs[e],batch_size[b],':',score[1])"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5895 - accuracy: 0.7986\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3706 - accuracy: 0.8702\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3226 - accuracy: 0.8869\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2905 - accuracy: 0.8972\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2725 - accuracy: 0.9033\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2500 - accuracy: 0.9115\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2404 - accuracy: 0.9138\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2243 - accuracy: 0.9206\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2150 - accuracy: 0.9242\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9265\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1917 - accuracy: 0.9316\n",
            "Adam 10 500 : 0.9316499829292297\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.7102 - accuracy: 0.7614\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8605\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8765\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.3211 - accuracy: 0.8879\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.3009 - accuracy: 0.8942\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2855 - accuracy: 0.8997\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2725 - accuracy: 0.9040\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2578 - accuracy: 0.9085\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2485 - accuracy: 0.9121\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2439 - accuracy: 0.9125\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2296 - accuracy: 0.9191\n",
            "Adam 10 1000 : 0.9190833568572998\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8091 - accuracy: 0.7414\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4361 - accuracy: 0.8488\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3861 - accuracy: 0.8665\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3536 - accuracy: 0.8778\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3359 - accuracy: 0.8827\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3192 - accuracy: 0.8880\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3024 - accuracy: 0.8946\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2938 - accuracy: 0.8967\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2854 - accuracy: 0.8999\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2757 - accuracy: 0.9020\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2663 - accuracy: 0.9060\n",
            "Adam 10 1500 : 0.906000018119812\n",
            "Epoch 1/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.8082\n",
            "Epoch 2/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3546 - accuracy: 0.8755\n",
            "Epoch 3/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.8907\n",
            "Epoch 4/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2823 - accuracy: 0.8998\n",
            "Epoch 5/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2581 - accuracy: 0.9085\n",
            "Epoch 6/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2437 - accuracy: 0.9134\n",
            "Epoch 7/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9175\n",
            "Epoch 8/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2199 - accuracy: 0.9205\n",
            "Epoch 9/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9261\n",
            "Epoch 10/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1960 - accuracy: 0.9300\n",
            "Epoch 11/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1848 - accuracy: 0.9343\n",
            "Epoch 12/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9382\n",
            "Epoch 13/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1661 - accuracy: 0.9408\n",
            "Epoch 14/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1596 - accuracy: 0.9438\n",
            "Epoch 15/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1510 - accuracy: 0.9464\n",
            "Epoch 16/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1429 - accuracy: 0.9494\n",
            "Epoch 17/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1352 - accuracy: 0.9524\n",
            "Epoch 18/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1280 - accuracy: 0.9555\n",
            "Epoch 19/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1236 - accuracy: 0.9571\n",
            "Epoch 20/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9603\n",
            "Epoch 21/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1114 - accuracy: 0.9618\n",
            "Epoch 22/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9645\n",
            "Epoch 23/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9661\n",
            "Epoch 24/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9682\n",
            "Epoch 25/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 0.9699\n",
            "Epoch 26/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0815 - accuracy: 0.9731\n",
            "Epoch 27/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0771 - accuracy: 0.9753\n",
            "Epoch 28/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0736 - accuracy: 0.9756\n",
            "Epoch 29/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0687 - accuracy: 0.9779\n",
            "Epoch 30/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 0.9800\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0542 - accuracy: 0.9845\n",
            "Adam 30 500 : 0.984499990940094\n",
            "Epoch 1/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6995 - accuracy: 0.7660\n",
            "Epoch 2/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8600\n",
            "Epoch 3/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3599 - accuracy: 0.8738\n",
            "Epoch 4/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.8875\n",
            "Epoch 5/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3072 - accuracy: 0.8925\n",
            "Epoch 6/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2899 - accuracy: 0.8987\n",
            "Epoch 7/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2734 - accuracy: 0.9032\n",
            "Epoch 8/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2660 - accuracy: 0.9061\n",
            "Epoch 9/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2544 - accuracy: 0.9106\n",
            "Epoch 10/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2472 - accuracy: 0.9124\n",
            "Epoch 11/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2329 - accuracy: 0.9181\n",
            "Epoch 12/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2262 - accuracy: 0.9197\n",
            "Epoch 13/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2212 - accuracy: 0.9212\n",
            "Epoch 14/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2100 - accuracy: 0.9270\n",
            "Epoch 15/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2047 - accuracy: 0.9276\n",
            "Epoch 16/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2005 - accuracy: 0.9291\n",
            "Epoch 17/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1910 - accuracy: 0.9322\n",
            "Epoch 18/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1844 - accuracy: 0.9352\n",
            "Epoch 19/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1853 - accuracy: 0.9339\n",
            "Epoch 20/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1776 - accuracy: 0.9371\n",
            "Epoch 21/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.9409\n",
            "Epoch 22/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1644 - accuracy: 0.9418\n",
            "Epoch 23/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1579 - accuracy: 0.9440\n",
            "Epoch 24/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9457\n",
            "Epoch 25/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1524 - accuracy: 0.9470\n",
            "Epoch 26/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1454 - accuracy: 0.9485\n",
            "Epoch 27/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.9502\n",
            "Epoch 28/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.9513\n",
            "Epoch 29/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1316 - accuracy: 0.9536\n",
            "Epoch 30/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1290 - accuracy: 0.9555\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1261 - accuracy: 0.9566\n",
            "Adam 30 1000 : 0.9566333293914795\n",
            "Epoch 1/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8795 - accuracy: 0.7196\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4452 - accuracy: 0.8457\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3806 - accuracy: 0.8665\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3417 - accuracy: 0.8796\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3168 - accuracy: 0.8883\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2988 - accuracy: 0.8945\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2872 - accuracy: 0.8980\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2735 - accuracy: 0.9036\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2697 - accuracy: 0.9031\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2557 - accuracy: 0.9087\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2436 - accuracy: 0.9136\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2404 - accuracy: 0.9140\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2298 - accuracy: 0.9185\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2225 - accuracy: 0.9211\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2189 - accuracy: 0.9224\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2115 - accuracy: 0.9249\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2074 - accuracy: 0.9265\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2045 - accuracy: 0.9272\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1949 - accuracy: 0.9314\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1913 - accuracy: 0.9323\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1879 - accuracy: 0.9335\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1810 - accuracy: 0.9367\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1790 - accuracy: 0.9373\n",
            "Epoch 24/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1738 - accuracy: 0.9398\n",
            "Epoch 25/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1681 - accuracy: 0.9412\n",
            "Epoch 26/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1657 - accuracy: 0.9422\n",
            "Epoch 27/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1620 - accuracy: 0.9432\n",
            "Epoch 28/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1561 - accuracy: 0.9461\n",
            "Epoch 29/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1524 - accuracy: 0.9474\n",
            "Epoch 30/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1504 - accuracy: 0.9474\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1420 - accuracy: 0.9521\n",
            "Adam 30 1500 : 0.9521333575248718\n",
            "Epoch 1/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5935 - accuracy: 0.7990\n",
            "Epoch 2/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3549 - accuracy: 0.8767\n",
            "Epoch 3/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3113 - accuracy: 0.8907\n",
            "Epoch 4/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.8989\n",
            "Epoch 5/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2610 - accuracy: 0.9074\n",
            "Epoch 6/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2465 - accuracy: 0.9124\n",
            "Epoch 7/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2339 - accuracy: 0.9170\n",
            "Epoch 8/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2166 - accuracy: 0.9227\n",
            "Epoch 9/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2065 - accuracy: 0.9264\n",
            "Epoch 10/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1974 - accuracy: 0.9296\n",
            "Epoch 11/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1864 - accuracy: 0.9335\n",
            "Epoch 12/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9356\n",
            "Epoch 13/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1683 - accuracy: 0.9403\n",
            "Epoch 14/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9412\n",
            "Epoch 15/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9465\n",
            "Epoch 16/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9485\n",
            "Epoch 17/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1402 - accuracy: 0.9498\n",
            "Epoch 18/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1359 - accuracy: 0.9520\n",
            "Epoch 19/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1267 - accuracy: 0.9563\n",
            "Epoch 20/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1195 - accuracy: 0.9586\n",
            "Epoch 21/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1137 - accuracy: 0.9607\n",
            "Epoch 22/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9620\n",
            "Epoch 23/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9650\n",
            "Epoch 24/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0982 - accuracy: 0.9664\n",
            "Epoch 25/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9679\n",
            "Epoch 26/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9699\n",
            "Epoch 27/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0816 - accuracy: 0.9722\n",
            "Epoch 28/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9743\n",
            "Epoch 29/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0723 - accuracy: 0.9759\n",
            "Epoch 30/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9763\n",
            "Epoch 31/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0648 - accuracy: 0.9790\n",
            "Epoch 32/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0595 - accuracy: 0.9811\n",
            "Epoch 33/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0597 - accuracy: 0.9808\n",
            "Epoch 34/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0557 - accuracy: 0.9822\n",
            "Epoch 35/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0498 - accuracy: 0.9848\n",
            "Epoch 36/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0465 - accuracy: 0.9862\n",
            "Epoch 37/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0448 - accuracy: 0.9866\n",
            "Epoch 38/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0399 - accuracy: 0.9887\n",
            "Epoch 39/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0371 - accuracy: 0.9900\n",
            "Epoch 40/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0362 - accuracy: 0.9896\n",
            "Epoch 41/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0342 - accuracy: 0.9905\n",
            "Epoch 42/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0324 - accuracy: 0.9915\n",
            "Epoch 43/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0294 - accuracy: 0.9924\n",
            "Epoch 44/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9930\n",
            "Epoch 45/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0234 - accuracy: 0.9944\n",
            "Epoch 46/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9941\n",
            "Epoch 47/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9922\n",
            "Epoch 48/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0185 - accuracy: 0.9959\n",
            "Epoch 49/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0181 - accuracy: 0.9961\n",
            "Epoch 50/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9966\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0179 - accuracy: 0.9961\n",
            "Adam 50 500 : 0.9961333274841309\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6995 - accuracy: 0.7609\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8558\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3647 - accuracy: 0.8729\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.8827\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.8874\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2964 - accuracy: 0.8946\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2802 - accuracy: 0.9003\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2685 - accuracy: 0.9049\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2609 - accuracy: 0.9073\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.9112\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2382 - accuracy: 0.9153\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2316 - accuracy: 0.9171\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2197 - accuracy: 0.9225\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2187 - accuracy: 0.9212\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.2104 - accuracy: 0.9252\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2062 - accuracy: 0.9270\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1979 - accuracy: 0.9293\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1927 - accuracy: 0.9304\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1869 - accuracy: 0.9333\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1827 - accuracy: 0.9354\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1789 - accuracy: 0.9361\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1689 - accuracy: 0.9405\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1696 - accuracy: 0.9397\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9406\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1584 - accuracy: 0.9442\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1516 - accuracy: 0.9467\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1498 - accuracy: 0.9483\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1447 - accuracy: 0.9495\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1403 - accuracy: 0.9510\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1366 - accuracy: 0.9536\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1338 - accuracy: 0.9536\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1333 - accuracy: 0.9532\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1269 - accuracy: 0.9560\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1216 - accuracy: 0.9586\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1212 - accuracy: 0.9581\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1152 - accuracy: 0.9612\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1155 - accuracy: 0.9599\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1093 - accuracy: 0.9628\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1122 - accuracy: 0.9609\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9646\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1049 - accuracy: 0.9634\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0964 - accuracy: 0.9688\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0920 - accuracy: 0.9701\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0916 - accuracy: 0.9697\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9718\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9725\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0817 - accuracy: 0.9743\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0800 - accuracy: 0.9743\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0767 - accuracy: 0.9760\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9766\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0690 - accuracy: 0.9788\n",
            "Adam 50 1000 : 0.9788166880607605\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7923 - accuracy: 0.7610\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4118 - accuracy: 0.8571\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3630 - accuracy: 0.8737\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3382 - accuracy: 0.8811\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3205 - accuracy: 0.8875\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8942\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2875 - accuracy: 0.8993\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2735 - accuracy: 0.9042\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2640 - accuracy: 0.9083\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2546 - accuracy: 0.9111\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2476 - accuracy: 0.9126\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2390 - accuracy: 0.9155\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2305 - accuracy: 0.9179\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2234 - accuracy: 0.9209\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2191 - accuracy: 0.9226\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2129 - accuracy: 0.9244\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2051 - accuracy: 0.9279\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1982 - accuracy: 0.9313\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1930 - accuracy: 0.9318\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1889 - accuracy: 0.9338\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1815 - accuracy: 0.9359\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1826 - accuracy: 0.9355\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1758 - accuracy: 0.9387\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1699 - accuracy: 0.9411\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1637 - accuracy: 0.9433\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1593 - accuracy: 0.9448\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1561 - accuracy: 0.9446\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1543 - accuracy: 0.9464\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1496 - accuracy: 0.9476\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1453 - accuracy: 0.9500\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1427 - accuracy: 0.9503\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1382 - accuracy: 0.9523\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1329 - accuracy: 0.9543\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1310 - accuracy: 0.9553\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1272 - accuracy: 0.9560\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1260 - accuracy: 0.9566\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9585\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1182 - accuracy: 0.9595\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1171 - accuracy: 0.9603\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1117 - accuracy: 0.9627\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9617\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 0.9635\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1060 - accuracy: 0.9646\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1081 - accuracy: 0.9625\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0999 - accuracy: 0.9669\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.9694\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0920 - accuracy: 0.9709\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9699\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0901 - accuracy: 0.9715\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.9694\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0828 - accuracy: 0.9743\n",
            "Adam 50 1500 : 0.9743166565895081\n",
            "Epoch 1/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.7713\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3904 - accuracy: 0.8611\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3267 - accuracy: 0.8836\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2919 - accuracy: 0.8946\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2656 - accuracy: 0.9037\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2440 - accuracy: 0.9111\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9167\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9232\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1990 - accuracy: 0.9274\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1867 - accuracy: 0.9308\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1756 - accuracy: 0.9366\n",
            "RMSprop 10 500 : 0.9366499781608582\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.7684 - accuracy: 0.7344\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.8344\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3920 - accuracy: 0.8604\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3461 - accuracy: 0.8773\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.8864\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2948 - accuracy: 0.8950\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2771 - accuracy: 0.8992\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2638 - accuracy: 0.9042\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2487 - accuracy: 0.9095\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2377 - accuracy: 0.9140\n",
            "   1/1875 [..............................] - ETA: 0s - loss: 0.1651 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0034s). Check your callbacks.\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2301 - accuracy: 0.9153\n",
            "RMSprop 10 1000 : 0.9153333306312561\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9058 - accuracy: 0.6961\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.5214 - accuracy: 0.8122\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4389 - accuracy: 0.8423\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3932 - accuracy: 0.8576\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3595 - accuracy: 0.8725\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3381 - accuracy: 0.8779\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3168 - accuracy: 0.8863\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3012 - accuracy: 0.8913\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2885 - accuracy: 0.8954\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2764 - accuracy: 0.8996\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2713 - accuracy: 0.9011\n",
            "RMSprop 10 1500 : 0.9011333584785461\n",
            "Epoch 1/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6427 - accuracy: 0.7744\n",
            "Epoch 2/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3918 - accuracy: 0.8605\n",
            "Epoch 3/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.8811\n",
            "Epoch 4/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2949 - accuracy: 0.8945\n",
            "Epoch 5/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2695 - accuracy: 0.9036\n",
            "Epoch 6/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2507 - accuracy: 0.9085\n",
            "Epoch 7/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2308 - accuracy: 0.9158\n",
            "Epoch 8/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2164 - accuracy: 0.9213\n",
            "Epoch 9/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2025 - accuracy: 0.9253\n",
            "Epoch 10/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1902 - accuracy: 0.9307\n",
            "Epoch 11/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1784 - accuracy: 0.9344\n",
            "Epoch 12/30\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.1702 - accuracy: 0.9374\n",
            "Epoch 13/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1595 - accuracy: 0.9423\n",
            "Epoch 14/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1489 - accuracy: 0.9457\n",
            "Epoch 15/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1423 - accuracy: 0.9484\n",
            "Epoch 16/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1340 - accuracy: 0.9515\n",
            "Epoch 17/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1279 - accuracy: 0.9535\n",
            "Epoch 18/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1195 - accuracy: 0.9570\n",
            "Epoch 19/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1136 - accuracy: 0.9588\n",
            "Epoch 20/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9610\n",
            "Epoch 21/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1003 - accuracy: 0.9635\n",
            "Epoch 22/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9665\n",
            "Epoch 23/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9684\n",
            "Epoch 24/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0836 - accuracy: 0.9701\n",
            "Epoch 25/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0796 - accuracy: 0.9724\n",
            "Epoch 26/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0748 - accuracy: 0.9734\n",
            "Epoch 27/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.9752\n",
            "Epoch 28/30\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0673 - accuracy: 0.9758\n",
            "Epoch 29/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 0.9787\n",
            "Epoch 30/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0595 - accuracy: 0.9792\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0436 - accuracy: 0.9878\n",
            "RMSprop 30 500 : 0.987766683101654\n",
            "Epoch 1/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.8038 - accuracy: 0.7204\n",
            "Epoch 2/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.8263\n",
            "Epoch 3/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.8557\n",
            "Epoch 4/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3574 - accuracy: 0.8717\n",
            "Epoch 5/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8818\n",
            "Epoch 6/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3003 - accuracy: 0.8924\n",
            "Epoch 7/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2835 - accuracy: 0.8976\n",
            "Epoch 8/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2687 - accuracy: 0.9028\n",
            "Epoch 9/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2522 - accuracy: 0.9090\n",
            "Epoch 10/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2405 - accuracy: 0.9112\n",
            "Epoch 11/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2303 - accuracy: 0.9161\n",
            "Epoch 12/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2200 - accuracy: 0.9198\n",
            "Epoch 13/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2128 - accuracy: 0.9217\n",
            "Epoch 14/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2041 - accuracy: 0.9252\n",
            "Epoch 15/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 0.9270\n",
            "Epoch 16/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1868 - accuracy: 0.9314\n",
            "Epoch 17/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1820 - accuracy: 0.9333\n",
            "Epoch 18/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1745 - accuracy: 0.9369\n",
            "Epoch 19/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1681 - accuracy: 0.9394\n",
            "Epoch 20/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.9399\n",
            "Epoch 21/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9424\n",
            "Epoch 22/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1534 - accuracy: 0.9437\n",
            "Epoch 23/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.9484\n",
            "Epoch 24/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1414 - accuracy: 0.9480\n",
            "Epoch 25/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1352 - accuracy: 0.9508\n",
            "Epoch 26/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1334 - accuracy: 0.9517\n",
            "Epoch 27/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1254 - accuracy: 0.9545\n",
            "Epoch 28/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1238 - accuracy: 0.9549\n",
            "Epoch 29/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1176 - accuracy: 0.9575\n",
            "Epoch 30/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1149 - accuracy: 0.9584\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0921 - accuracy: 0.9699\n",
            "RMSprop 30 1000 : 0.9698833227157593\n",
            "Epoch 1/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9908 - accuracy: 0.6693\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.5804 - accuracy: 0.7906\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4849 - accuracy: 0.8254\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4235 - accuracy: 0.8480\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3825 - accuracy: 0.8638\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3558 - accuracy: 0.8737\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3330 - accuracy: 0.8814\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3173 - accuracy: 0.8866\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2991 - accuracy: 0.8913\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2857 - accuracy: 0.8974\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2729 - accuracy: 0.9013\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2644 - accuracy: 0.9043\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2536 - accuracy: 0.9088\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2432 - accuracy: 0.9112\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2371 - accuracy: 0.9123\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2278 - accuracy: 0.9174\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2209 - accuracy: 0.9197\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2150 - accuracy: 0.9216\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2078 - accuracy: 0.9240\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2040 - accuracy: 0.9250\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1961 - accuracy: 0.9280\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1906 - accuracy: 0.9304\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1856 - accuracy: 0.9316\n",
            "Epoch 24/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1800 - accuracy: 0.9337\n",
            "Epoch 25/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1769 - accuracy: 0.9354\n",
            "Epoch 26/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1715 - accuracy: 0.9377\n",
            "Epoch 27/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1658 - accuracy: 0.9386\n",
            "Epoch 28/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1640 - accuracy: 0.9404\n",
            "Epoch 29/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9433\n",
            "Epoch 30/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1563 - accuracy: 0.9432\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1329 - accuracy: 0.9545\n",
            "RMSprop 30 1500 : 0.9545333385467529\n",
            "Epoch 1/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6516 - accuracy: 0.7736\n",
            "Epoch 2/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3899 - accuracy: 0.8606\n",
            "Epoch 3/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3222 - accuracy: 0.8853\n",
            "Epoch 4/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2873 - accuracy: 0.8976\n",
            "Epoch 5/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2632 - accuracy: 0.9050\n",
            "Epoch 6/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2445 - accuracy: 0.9109\n",
            "Epoch 7/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9166\n",
            "Epoch 8/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2117 - accuracy: 0.9222\n",
            "Epoch 9/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1992 - accuracy: 0.9271\n",
            "Epoch 10/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9316\n",
            "Epoch 11/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9345\n",
            "Epoch 12/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1675 - accuracy: 0.9386\n",
            "Epoch 13/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.9420\n",
            "Epoch 14/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1497 - accuracy: 0.9452\n",
            "Epoch 15/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1413 - accuracy: 0.9489\n",
            "Epoch 16/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1344 - accuracy: 0.9512\n",
            "Epoch 17/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1279 - accuracy: 0.9539\n",
            "Epoch 18/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1212 - accuracy: 0.9562\n",
            "Epoch 19/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1143 - accuracy: 0.9588\n",
            "Epoch 20/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9612\n",
            "Epoch 21/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9636\n",
            "Epoch 22/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0970 - accuracy: 0.9651\n",
            "Epoch 23/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9681\n",
            "Epoch 24/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0859 - accuracy: 0.9695\n",
            "Epoch 25/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9720\n",
            "Epoch 26/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0762 - accuracy: 0.9737\n",
            "Epoch 27/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0720 - accuracy: 0.9753\n",
            "Epoch 28/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0675 - accuracy: 0.9767\n",
            "Epoch 29/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 0.9766\n",
            "Epoch 30/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 0.9796\n",
            "Epoch 31/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9803\n",
            "Epoch 32/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9817\n",
            "Epoch 33/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9835\n",
            "Epoch 34/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0473 - accuracy: 0.9841\n",
            "Epoch 35/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0437 - accuracy: 0.9857\n",
            "Epoch 36/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0399 - accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0391 - accuracy: 0.9874\n",
            "Epoch 38/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0382 - accuracy: 0.9879\n",
            "Epoch 39/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0337 - accuracy: 0.9890\n",
            "Epoch 40/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0309 - accuracy: 0.9900\n",
            "Epoch 42/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9915\n",
            "Epoch 43/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0271 - accuracy: 0.9914\n",
            "Epoch 44/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0249 - accuracy: 0.9922\n",
            "Epoch 45/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0248 - accuracy: 0.9921\n",
            "Epoch 46/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9933\n",
            "Epoch 47/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9939\n",
            "Epoch 48/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0212 - accuracy: 0.9940\n",
            "Epoch 49/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9935\n",
            "Epoch 50/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9950\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0087 - accuracy: 0.9984\n",
            "RMSprop 50 500 : 0.9983500242233276\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.8021 - accuracy: 0.7290\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4780 - accuracy: 0.8293\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8595\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3533 - accuracy: 0.8736\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.3216 - accuracy: 0.8862\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2989 - accuracy: 0.8935\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2799 - accuracy: 0.8999\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2684 - accuracy: 0.9038\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2514 - accuracy: 0.9099\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2413 - accuracy: 0.9129\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2308 - accuracy: 0.9165\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2227 - accuracy: 0.9190\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2126 - accuracy: 0.9231\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.2041 - accuracy: 0.9259\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1985 - accuracy: 0.9264\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1880 - accuracy: 0.9312\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1835 - accuracy: 0.9320\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1760 - accuracy: 0.9355\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1686 - accuracy: 0.9385\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1629 - accuracy: 0.9407\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1584 - accuracy: 0.9421\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1526 - accuracy: 0.9436\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.9468\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1439 - accuracy: 0.9477\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1361 - accuracy: 0.9503\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 0.9525\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 0.9528\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1238 - accuracy: 0.9546\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1200 - accuracy: 0.9574\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1149 - accuracy: 0.9583\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1103 - accuracy: 0.9598\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1109 - accuracy: 0.9600\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1012 - accuracy: 0.9640\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 0.9631\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0947 - accuracy: 0.9661\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0879 - accuracy: 0.9690\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9688\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0840 - accuracy: 0.9707\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9706\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0771 - accuracy: 0.9734\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9738\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9737\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0672 - accuracy: 0.9766\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 0.9773\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0653 - accuracy: 0.9773\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 0.9779\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9803\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9799\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9813\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0408 - accuracy: 0.9881\n",
            "RMSprop 50 1000 : 0.9881166815757751\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9314 - accuracy: 0.6823\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.5415 - accuracy: 0.8023\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4528 - accuracy: 0.8348\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3976 - accuracy: 0.8586\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3643 - accuracy: 0.8695\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3379 - accuracy: 0.8797\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3171 - accuracy: 0.8855\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3025 - accuracy: 0.8906\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2900 - accuracy: 0.8963\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2738 - accuracy: 0.9023\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2647 - accuracy: 0.9046\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2536 - accuracy: 0.9082\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2459 - accuracy: 0.9100\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2377 - accuracy: 0.9129\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2283 - accuracy: 0.9184\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2211 - accuracy: 0.9192\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2162 - accuracy: 0.9205\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2092 - accuracy: 0.9239\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2010 - accuracy: 0.9264\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1968 - accuracy: 0.9287\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1926 - accuracy: 0.9296\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1828 - accuracy: 0.9335\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1804 - accuracy: 0.9343\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1759 - accuracy: 0.9362\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1694 - accuracy: 0.9388\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1684 - accuracy: 0.9391\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1613 - accuracy: 0.9414\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1588 - accuracy: 0.9421\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1563 - accuracy: 0.9431\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1484 - accuracy: 0.9465\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1448 - accuracy: 0.9481\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1417 - accuracy: 0.9491\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1402 - accuracy: 0.9492\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1337 - accuracy: 0.9520\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1321 - accuracy: 0.9526\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1276 - accuracy: 0.9534\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1239 - accuracy: 0.9556\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1227 - accuracy: 0.9557\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1187 - accuracy: 0.9568\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1140 - accuracy: 0.9591\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1127 - accuracy: 0.9587\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1079 - accuracy: 0.9613\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1056 - accuracy: 0.9623\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1040 - accuracy: 0.9630\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 0.9631\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.9658\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0971 - accuracy: 0.9653\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.0920 - accuracy: 0.9675\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0886 - accuracy: 0.9683\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.0900 - accuracy: 0.9678\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0699 - accuracy: 0.9782\n",
            "RMSprop 50 1500 : 0.9781833291053772\n",
            "Epoch 1/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.7395 - accuracy: 0.4904\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.8976 - accuracy: 0.7003\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.7190 - accuracy: 0.7504\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6462 - accuracy: 0.7758\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6061 - accuracy: 0.7869\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5782 - accuracy: 0.7966\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5597 - accuracy: 0.8016\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.8070\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.8104\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5215 - accuracy: 0.8144\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5190 - accuracy: 0.8156\n",
            "SGD 10 500 : 0.8156333565711975\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 2.0622 - accuracy: 0.3006\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 1.3936 - accuracy: 0.5938\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.9737 - accuracy: 0.6900\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.8155 - accuracy: 0.7316\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.7364 - accuracy: 0.7541\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.6865 - accuracy: 0.7678\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6511 - accuracy: 0.7779\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.6253 - accuracy: 0.7837\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.6028 - accuracy: 0.7908\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5883 - accuracy: 0.7939\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5793 - accuracy: 0.7954\n",
            "SGD 10 1000 : 0.795366644859314\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 2.1894 - accuracy: 0.2801\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.8536 - accuracy: 0.5219\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.3867 - accuracy: 0.6354\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.0738 - accuracy: 0.6680\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9199 - accuracy: 0.6942\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8330 - accuracy: 0.7224\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7761 - accuracy: 0.7414\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7343 - accuracy: 0.7562\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7026 - accuracy: 0.7651\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6756 - accuracy: 0.7729\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6642 - accuracy: 0.7764\n",
            "SGD 10 1500 : 0.7763500213623047\n",
            "Epoch 1/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.6641 - accuracy: 0.5477\n",
            "Epoch 2/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.8909 - accuracy: 0.6976\n",
            "Epoch 3/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.7272 - accuracy: 0.7521\n",
            "Epoch 4/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6560 - accuracy: 0.7753\n",
            "Epoch 5/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6115 - accuracy: 0.7903\n",
            "Epoch 6/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5843 - accuracy: 0.7971\n",
            "Epoch 7/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5603 - accuracy: 0.8045\n",
            "Epoch 8/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.8115\n",
            "Epoch 9/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.8102\n",
            "Epoch 10/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5178 - accuracy: 0.8191\n",
            "Epoch 11/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.8193\n",
            "Epoch 12/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.8226\n",
            "Epoch 13/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.8257\n",
            "Epoch 14/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4883 - accuracy: 0.8272\n",
            "Epoch 15/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4818 - accuracy: 0.8299\n",
            "Epoch 16/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4756 - accuracy: 0.8329\n",
            "Epoch 17/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.8361\n",
            "Epoch 18/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4621 - accuracy: 0.8388\n",
            "Epoch 19/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.8383\n",
            "Epoch 20/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4570 - accuracy: 0.8391\n",
            "Epoch 21/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4518 - accuracy: 0.8417\n",
            "Epoch 22/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4510 - accuracy: 0.8403\n",
            "Epoch 23/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4419 - accuracy: 0.8454\n",
            "Epoch 24/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4401 - accuracy: 0.8458\n",
            "Epoch 25/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4349 - accuracy: 0.8473\n",
            "Epoch 26/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4323 - accuracy: 0.8485\n",
            "Epoch 27/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4312 - accuracy: 0.8489\n",
            "Epoch 28/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.8511\n",
            "Epoch 29/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.8512\n",
            "Epoch 30/30\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8541\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4758 - accuracy: 0.8280\n",
            "SGD 30 500 : 0.8279666900634766\n",
            "Epoch 1/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 1.9965 - accuracy: 0.4161\n",
            "Epoch 2/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 1.2699 - accuracy: 0.6483\n",
            "Epoch 3/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.9219 - accuracy: 0.6959\n",
            "Epoch 4/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.7979 - accuracy: 0.7318\n",
            "Epoch 5/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.7315 - accuracy: 0.7541\n",
            "Epoch 6/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.7681\n",
            "Epoch 7/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.6557 - accuracy: 0.7771\n",
            "Epoch 8/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.6298 - accuracy: 0.7852\n",
            "Epoch 9/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6112 - accuracy: 0.7900\n",
            "Epoch 10/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5938 - accuracy: 0.7939\n",
            "Epoch 11/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5786 - accuracy: 0.7995\n",
            "Epoch 12/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5646 - accuracy: 0.8034\n",
            "Epoch 13/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5571 - accuracy: 0.8044\n",
            "Epoch 14/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5540 - accuracy: 0.8051\n",
            "Epoch 15/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5466 - accuracy: 0.8077\n",
            "Epoch 16/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.8067\n",
            "Epoch 17/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5208 - accuracy: 0.8181\n",
            "Epoch 18/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.8104\n",
            "Epoch 19/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.8138\n",
            "Epoch 20/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5150 - accuracy: 0.8174\n",
            "Epoch 21/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.8197\n",
            "Epoch 22/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5071 - accuracy: 0.8194\n",
            "Epoch 23/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.8230\n",
            "Epoch 24/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4955 - accuracy: 0.8251\n",
            "Epoch 25/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4967 - accuracy: 0.8240\n",
            "Epoch 26/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.8234\n",
            "Epoch 27/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4828 - accuracy: 0.8301\n",
            "Epoch 28/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4855 - accuracy: 0.8281\n",
            "Epoch 29/30\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4802 - accuracy: 0.8298\n",
            "Epoch 30/30\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.8327\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4627 - accuracy: 0.8385\n",
            "SGD 30 1000 : 0.838450014591217\n",
            "Epoch 1/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 2.1882 - accuracy: 0.3168\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.8161 - accuracy: 0.5350\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.3433 - accuracy: 0.6334\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.0466 - accuracy: 0.6709\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9034 - accuracy: 0.7009\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8232 - accuracy: 0.7251\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7703 - accuracy: 0.7414\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7319 - accuracy: 0.7543\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7008 - accuracy: 0.7635\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6764 - accuracy: 0.7705\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.6555 - accuracy: 0.7763\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6383 - accuracy: 0.7811\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6238 - accuracy: 0.7850\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6104 - accuracy: 0.7889\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5979 - accuracy: 0.7930\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5874 - accuracy: 0.7963\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5785 - accuracy: 0.7988\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5746 - accuracy: 0.7982\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5625 - accuracy: 0.8041\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5626 - accuracy: 0.8009\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5540 - accuracy: 0.8050\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5482 - accuracy: 0.8077\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.5419 - accuracy: 0.8085\n",
            "Epoch 24/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5362 - accuracy: 0.8106\n",
            "Epoch 25/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5317 - accuracy: 0.8123\n",
            "Epoch 26/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5314 - accuracy: 0.8118\n",
            "Epoch 27/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5290 - accuracy: 0.8128\n",
            "Epoch 28/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5200 - accuracy: 0.8166\n",
            "Epoch 29/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5190 - accuracy: 0.8169\n",
            "Epoch 30/30\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5160 - accuracy: 0.8173\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5044 - accuracy: 0.8253\n",
            "SGD 30 1500 : 0.8253166675567627\n",
            "Epoch 1/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.7257 - accuracy: 0.5119\n",
            "Epoch 2/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.9032 - accuracy: 0.7030\n",
            "Epoch 3/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.7205 - accuracy: 0.7571\n",
            "Epoch 4/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6456 - accuracy: 0.7804\n",
            "Epoch 5/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.7915\n",
            "Epoch 6/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5739 - accuracy: 0.7987\n",
            "Epoch 7/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5547 - accuracy: 0.8052\n",
            "Epoch 8/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.8103\n",
            "Epoch 9/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5243 - accuracy: 0.8151\n",
            "Epoch 10/50\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.5158 - accuracy: 0.8164\n",
            "Epoch 11/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8205\n",
            "Epoch 12/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5032 - accuracy: 0.8209\n",
            "Epoch 13/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4860 - accuracy: 0.8288\n",
            "Epoch 14/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.8288\n",
            "Epoch 15/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.8345\n",
            "Epoch 16/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.8333\n",
            "Epoch 17/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.8371\n",
            "Epoch 18/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4627 - accuracy: 0.8365\n",
            "Epoch 19/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4573 - accuracy: 0.8388\n",
            "Epoch 20/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4490 - accuracy: 0.8421\n",
            "Epoch 21/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4539 - accuracy: 0.8399\n",
            "Epoch 22/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4421 - accuracy: 0.8448\n",
            "Epoch 23/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4403 - accuracy: 0.8454\n",
            "Epoch 24/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4321 - accuracy: 0.8476\n",
            "Epoch 25/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8503\n",
            "Epoch 26/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8495\n",
            "Epoch 27/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4248 - accuracy: 0.8509\n",
            "Epoch 28/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8540\n",
            "Epoch 29/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4193 - accuracy: 0.8525\n",
            "Epoch 30/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8544\n",
            "Epoch 31/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8561\n",
            "Epoch 32/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8550\n",
            "Epoch 33/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8570\n",
            "Epoch 34/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8575\n",
            "Epoch 35/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4024 - accuracy: 0.8587\n",
            "Epoch 36/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3996 - accuracy: 0.8590\n",
            "Epoch 37/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8612\n",
            "Epoch 38/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3919 - accuracy: 0.8626\n",
            "Epoch 39/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3942 - accuracy: 0.8617\n",
            "Epoch 40/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3893 - accuracy: 0.8640\n",
            "Epoch 41/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3922 - accuracy: 0.8625\n",
            "Epoch 42/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3894 - accuracy: 0.8641\n",
            "Epoch 43/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3802 - accuracy: 0.8672\n",
            "Epoch 44/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3814 - accuracy: 0.8665\n",
            "Epoch 45/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3779 - accuracy: 0.8685\n",
            "Epoch 46/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3770 - accuracy: 0.8678\n",
            "Epoch 47/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3738 - accuracy: 0.8692\n",
            "Epoch 48/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3766 - accuracy: 0.8674\n",
            "Epoch 49/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3685 - accuracy: 0.8704\n",
            "Epoch 50/50\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.8702\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3704 - accuracy: 0.8701\n",
            "SGD 50 500 : 0.8701333403587341\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 2.0949 - accuracy: 0.4004\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 1.3994 - accuracy: 0.6047\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.9774 - accuracy: 0.6812\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.8260 - accuracy: 0.7240\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.7497 - accuracy: 0.7456\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.6995 - accuracy: 0.7615\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6626 - accuracy: 0.7740\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6372 - accuracy: 0.7801\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6140 - accuracy: 0.7871\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.7900\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5863 - accuracy: 0.7936\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5792 - accuracy: 0.7953\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5644 - accuracy: 0.8014\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5527 - accuracy: 0.8044\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.8047\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5376 - accuracy: 0.8095\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5353 - accuracy: 0.8085\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5314 - accuracy: 0.8101\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.8106\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5135 - accuracy: 0.8187\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5135 - accuracy: 0.8186\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.8233\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8169\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.8229\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4988 - accuracy: 0.8236\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4978 - accuracy: 0.8228\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.8233\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.8265\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.8312\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.8308\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4846 - accuracy: 0.8263\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.8335\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.8337\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4666 - accuracy: 0.8361\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.8358\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.8339\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.8376\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4662 - accuracy: 0.8357\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4568 - accuracy: 0.8394\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.8381\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.8427\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.8446\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.8378\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.8391\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.8452\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8480\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4458 - accuracy: 0.8435\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8446\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.8434\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.8489\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4236 - accuracy: 0.8531\n",
            "SGD 50 1000 : 0.8531000018119812\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 2.1067 - accuracy: 0.2935\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.6529 - accuracy: 0.5727\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.2239 - accuracy: 0.6381\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9929 - accuracy: 0.6817\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8742 - accuracy: 0.7103\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8026 - accuracy: 0.7290\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7540 - accuracy: 0.7417\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7183 - accuracy: 0.7525\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6900 - accuracy: 0.7613\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6671 - accuracy: 0.7696\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6466 - accuracy: 0.7767\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6304 - accuracy: 0.7823\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.7871\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6038 - accuracy: 0.7904\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5910 - accuracy: 0.7968\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5820 - accuracy: 0.7975\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5713 - accuracy: 0.8017\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5643 - accuracy: 0.8034\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5586 - accuracy: 0.8042\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5520 - accuracy: 0.8068\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5460 - accuracy: 0.8086\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5426 - accuracy: 0.8094\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5388 - accuracy: 0.8099\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5325 - accuracy: 0.8125\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5265 - accuracy: 0.8156\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5220 - accuracy: 0.8151\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5236 - accuracy: 0.8145\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5193 - accuracy: 0.8155\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5137 - accuracy: 0.8187\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.8133\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.8223\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5101 - accuracy: 0.8179\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5095 - accuracy: 0.8181\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4946 - accuracy: 0.8263\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4916 - accuracy: 0.8279\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4999 - accuracy: 0.8227\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4912 - accuracy: 0.8264\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4970 - accuracy: 0.8221\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4877 - accuracy: 0.8277\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8284\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4925 - accuracy: 0.8245\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4846 - accuracy: 0.8286\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4826 - accuracy: 0.8288\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.8313\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4782 - accuracy: 0.8311\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4828 - accuracy: 0.8277\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4838 - accuracy: 0.8264\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4759 - accuracy: 0.8321\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4847 - accuracy: 0.8257\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4717 - accuracy: 0.8337\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4667 - accuracy: 0.8327\n",
            "SGD 50 1500 : 0.8327333331108093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK4lQS-0QcvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "13fe98e3-4cec-4b64-c772-73cd6f65cc48"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame.from_dict(result2,orient='index')"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adam10500</th>\n",
              "      <td>0.931650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam101000</th>\n",
              "      <td>0.919083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam101500</th>\n",
              "      <td>0.906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam30500</th>\n",
              "      <td>0.984500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam301000</th>\n",
              "      <td>0.956633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam301500</th>\n",
              "      <td>0.952133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam50500</th>\n",
              "      <td>0.996133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam501000</th>\n",
              "      <td>0.978817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam501500</th>\n",
              "      <td>0.974317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop10500</th>\n",
              "      <td>0.936650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop101000</th>\n",
              "      <td>0.915333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop101500</th>\n",
              "      <td>0.901133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop30500</th>\n",
              "      <td>0.987767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop301000</th>\n",
              "      <td>0.969883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop301500</th>\n",
              "      <td>0.954533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop50500</th>\n",
              "      <td>0.998350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop501000</th>\n",
              "      <td>0.988117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSprop501500</th>\n",
              "      <td>0.978183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD10500</th>\n",
              "      <td>0.815633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD101000</th>\n",
              "      <td>0.795367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD101500</th>\n",
              "      <td>0.776350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD30500</th>\n",
              "      <td>0.827967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD301000</th>\n",
              "      <td>0.838450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD301500</th>\n",
              "      <td>0.825317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD50500</th>\n",
              "      <td>0.870133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD501000</th>\n",
              "      <td>0.853100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD501500</th>\n",
              "      <td>0.832733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0\n",
              "Adam10500      0.931650\n",
              "Adam101000     0.919083\n",
              "Adam101500     0.906000\n",
              "Adam30500      0.984500\n",
              "Adam301000     0.956633\n",
              "Adam301500     0.952133\n",
              "Adam50500      0.996133\n",
              "Adam501000     0.978817\n",
              "Adam501500     0.974317\n",
              "RMSprop10500   0.936650\n",
              "RMSprop101000  0.915333\n",
              "RMSprop101500  0.901133\n",
              "RMSprop30500   0.987767\n",
              "RMSprop301000  0.969883\n",
              "RMSprop301500  0.954533\n",
              "RMSprop50500   0.998350\n",
              "RMSprop501000  0.988117\n",
              "RMSprop501500  0.978183\n",
              "SGD10500       0.815633\n",
              "SGD101000      0.795367\n",
              "SGD101500      0.776350\n",
              "SGD30500       0.827967\n",
              "SGD301000      0.838450\n",
              "SGD301500      0.825317\n",
              "SGD50500       0.870133\n",
              "SGD501000      0.853100\n",
              "SGD501500      0.832733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0hYl6BRe45W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}